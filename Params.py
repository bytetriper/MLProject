import torch
Params = {
    'lr': 5e-3,
    'device': 'cuda' if torch.cuda.is_available() else 'cpu',
    'save_generator': True,
    'load_generator': False,
    'generator_path': '/root/autodl-tmp/MLProject/models/generator.pth',
    'model_name': 'openai/clip-vit-base-patch16',
    'difuse_name': 'openai/clip-vit-base-patch16',
    'batch_size': 32,
    'epochs': 3,
    'select_col': 1,  # should be in range [0-4]
    'num_workers': 5,
    "noise_bound": 8/255,
    "train_dataset_path": "/root/autodl-tmp/datasets/ImageNet1k-split",
    "noised_dataset_path": "/root/autodl-tmp/datasets/ViT_30",
    "summary_path": "/root/autodl-tmp/MLProject/summary",
    "original_image_path": "/root/autodl-tmp/MLProject/imgs/source.png",
    "noised_image_path": "/root/autodl-tmp/MLProject/imgs/noised.png",
    "noise_image_path": "/root/autodl-tmp/MLProject/imgs/noise.png",
    "noise_path": "/root/autodl-tmp/MLProject/data/noise.npy",
    "last_epoch": 0,
    'step': 4,
    'opt_level': 'O2',
    'amp_mode': False,
    'ascented_image_path': "/root/autodl-tmp/MLProject/demo/ascented/",
    'original_image_path': "/root/autodl-tmp/MLProject/demo/original/",
    'noise_path': "/root/autodl-tmp/MLProject/demo/noise/",
    'difference_image_path': "/root/autodl-tmp/MLProject/demo/difference/",
}
